{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This code replicates the Google Colab topic modeling notebook for use on Jupyter Notebook or another local Python environment.\n",
    "\n",
    "Below, Gensim is used to create LDA topic models of a pre-loaded dataframe of texts. Methods for evaluating topic coherence and analyzing topic output are also demonstrated. \n",
    "\n",
    "This code is adapted from [Intro to Topic Modeling with Gensim and pyLDAvis](https://github.com/hawc2/text-analysis-with-python/blob/master/Topic_Modeling.ipynb) and works well with input from from the Text Sectioning and Disaggregation code from [this repository](https://github.com/SF-Nexus/Extracted-Features).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages\n",
    "This code requires three main packages:\n",
    "- **NLTK:** Cleaning disaggregated data\n",
    "- **Gensim:** Preprocessing data and creating word embeddings, coherence models and topic models\n",
    "- **LDAvis:** Visualizing topic models\n",
    "\n",
    "Several other packages for wrangling and processing the data, such as io and pandas, will also be installed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BEFORE USING THIS CODE FOR THE FIRST TIME**:\n",
    "\n",
    "This code was created using a Jupyter Notebook through Anaconda. Before running the code for the first time, **create a new environment in Anaconda** where all packages and libraries will be stored for future usages. Learn how to create an environment using Anaconda Navigator [here.](https://wiki.math.ntnu.no/anaconda/createenvironment)\n",
    "\n",
    "When using a new environment for the first time, several packages will need to be installed. It is recommended that you install these directly in the terminal rather than through Jupyter Notebook (though both are possible). To install in terminal, open a new terminal window, make sure you are in the correct environment, and input the following commands: \n",
    "\n",
    "```conda install nltk```\n",
    "```conda install gensim```\n",
    "```conda install pyLDAvis```\n",
    "\n",
    "Once these packages are installed, they can be imported below. *You only need to install these the FIRST time you are using this code in a new environment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dssadmin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (3.3.1)\n",
      "Requirement already satisfied: joblib in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: gensim in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (4.2.0)\n",
      "Requirement already satisfied: scipy in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (1.9.3)\n",
      "Requirement already satisfied: jinja2 in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (1.1.3)\n",
      "Requirement already satisfied: sklearn in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (0.0.post1)\n",
      "Requirement already satisfied: setuptools in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (65.5.0)\n",
      "Requirement already satisfied: numexpr in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (2.8.4)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (1.23.4)\n",
      "Requirement already satisfied: future in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (1.5.2)\n",
      "Requirement already satisfied: funcy in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pyLDAvis) (1.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from pandas>=1.2.0->pyLDAvis) (2022.6)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from jinja2->pyLDAvis) (2.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from scikit-learn->pyLDAvis) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyLDAvis) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dssadmin/anaconda3/envs/gensim_tm/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgensim_models\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgensimvis\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and Convert Corpus to Data Frame\n",
    "\n",
    "This code requires the upload of a previously created dataframe which contains a corpus of disaggregated texts. For optimal use, this dataframe should also contain labels associated with each text (e.g. book or chapter numbers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get current working directory \n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "#Change working directory\n",
    "path = os.chdir(\"/home/dssadmin/Desktop/ExtractedFeatures_test_directory\")\n",
    "\n",
    "#Upload dataframeâˆš\n",
    "df = pd.read_csv('chapter_chunks_agg_output.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bf1535a76b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Drop any empty cells\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Drop any empty cells\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add values in Text column to new list (for further cleaning)\n",
    "data = df.Text.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Texts\n",
    "Below are several preprocessing measures to help improve quality of text used for the topic model. Some may or may not be useful depending on specifications of corpus or goals of topic modeling:\n",
    "- **Stopword Removal:** Removes globally common words from corpus which may skew topics; some stopwords may be useful for analysis and some studies show that removing more than the top 10 most common words does not significantly impact topic model results \n",
    "- **Bigrams/Trigram Modeling:** Recognizes common 2- and 3-word phrases to prevent disambiguation (e.g. spaceship vs. space, ship); may misidentify phrases especially in corpora with large/uncommon vocabularies like sci-fi\n",
    "- **Lemmatization:** Transforms words to root form to aid recognition; some studies show may be redundant, unnecessary or even inaccurate in conflating differing words with same root meanings \n",
    "\n",
    "*Read More:*\n",
    "\n",
    "https://maria-antoniak.github.io/2022/07/27/topic-modeling-for-the-people.html\n",
    "\n",
    "https://towardsdatascience.com/6-tips-to-optimize-an-nlp-topic-model-for-interpretability-20742f3047e2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define list of stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Add further stopwords by simply \"appending\" desired words to dictionary\n",
    "stop_words.append('CHAPTER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to perform simple preprocessing on text\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "      yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run processing function on texts\n",
    "data_words = list(sent_to_words(data))\n",
    "#print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define stopword removal\n",
    "def remove_stopwords(texts):\n",
    "   return [[word for word in simple_preprocess(str(doc))\n",
    "if word not in stop_words] for doc in texts]\n",
    "\n",
    "#Define function to make bigrams\n",
    "def make_bigrams(texts):\n",
    "   return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "#def make_trigrams(texts):\n",
    "#   return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "#Define function to lemmatize texts\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "   texts_out = []\n",
    "   for sent in texts:\n",
    "     doc = nlp(\" \".join(sent))\n",
    "     texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "   return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=1, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run functions to remove stopwords, make bigrams, and lemmatize text\n",
    "data_words = remove_stopwords(data_words)\n",
    "#data_words_bigrams = make_bigrams(data_nostops)\n",
    "#data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "#print(data_lemmatized[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Dictionary and Corpus\n",
    "Once the dataset is cleaned, two inputs must be created to run the topic model. Creating the dictionary maps every word in the corpus with a unique id number. The variable corpus is calculated by determining the frequency of each word in the document. Another optional cleaning measure can be used here--removing words that are extremely rare (existing in < n number of texts) or common (existing in > n number of texts).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dictionary\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(data_words)\n",
    "\n",
    "#Calculate term document frequency for each word in dataset\n",
    "corpus = [dictionary.doc2bow(doc) for doc in data_words]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL cleaning: filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "#dictionary.filter_extremes(no_below=2, no_above=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of unique tokens and documents\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Optimal Number of Topics\n",
    "\n",
    "Calculating topic model coherence (i.e. similarity between the highest-scoring words in each topic) is one way to assess the optimal number of topics to use when creating and visualizing topic models. Below are two methods of calculating coherence: **C_V coherence**, which is calculated based on word co-occurences, and **U_Mass coherence**, which is calculated based on how frequently documents containing high-scoring words co-occur in the corpus. Both have been used in prior research and either may yield better results, depending on corpus specifications.\n",
    "\n",
    "Additional readings: \n",
    "\n",
    "https://aclanthology.org/D12-1087.pdf \n",
    "\n",
    "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C_V Coherence Calculations\n",
    "\n",
    "The function below calculates C_V coherence scores for n topic models run based on set parameters. Coherence is calculated on a range of 0 < x < 1 where higher-scoring models are assumed more coherent. For example, a model with a score of .50 is more coherent than a model with a .25 score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define list for model and coherence values\n",
    "coherence = []\n",
    "\n",
    "#Find coherence for set range of models and append to list\n",
    "for k in range(2,200):\n",
    "    print('Round: '+str(k))\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "    ldamodel = Lda(corpus, num_topics=k, \\\n",
    "               id2word = dictionary, eval_every = None)\n",
    "    \n",
    "    cm = gensim.models.coherencemodel.CoherenceModel(\\\n",
    "         model=ldamodel, texts=data_words,\\\n",
    "         dictionary=dictionary, coherence='c_v')   \n",
    "                                                \n",
    "    coherence.append((k,cm.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose coherence data\n",
    "x, y = np.array(coherence).T\n",
    "  \n",
    "      \n",
    "# plot our list in X,Y coordinates\n",
    "optimal, = plt.plot(x, y)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get coherence score for each num topics sorted from highest to lowest\n",
    "#Highest value will be optimal number of topics\n",
    "Data = {'Num Topics': optimal.get_xdata(), 'Coherence': optimal.get_ydata()}\n",
    "type(Data)\n",
    "df_optimal = pd.DataFrame.from_dict(Data)\n",
    "df_optimal.sort_values(by='Coherence',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U_Mass Coherence Calculation\n",
    "The function below calculates U_Mass coherence scores of n topic models run based on set parameters. Coherence is calculated on a range of -14 < x < 14 where lower-scoring models are more coherent. For example, a model with a score of -.4 is less coherent than a model with a -.9 score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define list for model and coherence values\n",
    "coherence2 = []\n",
    "\n",
    "#Find coherence for set range of models and append to list\n",
    "for k in range(2,100):\n",
    "    print('Round: '+str(k))\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "    ldamodel = Lda(corpus, num_topics=k, \\\n",
    "               id2word = dictionary, eval_every = None)\n",
    "    \n",
    "    cm = gensim.models.coherencemodel.CoherenceModel(\\\n",
    "         model=ldamodel, texts=data_words,\\\n",
    "         dictionary=dictionary, coherence='u_mass')   \n",
    "                                                \n",
    "    coherence2.append((k,cm.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose coherence data\n",
    "x, y = np.array(coherence2).T\n",
    "        \n",
    "# plot our list in X,Y coordinates\n",
    "optimal2, = plt.plot(x, y)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get coherence score for each num topics sorted from highest to lowest\n",
    "#Lowest value will be optimal number of topics\n",
    "Data = {'Num Topics': optimal2.get_xdata(), 'Coherence': optimal2.get_ydata()}\n",
    "type(Data)\n",
    "df_optimal2 = pd.DataFrame.from_dict(Data)\n",
    "df_optimal2.sort_values(by='Coherence',ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Topic Models with Optimal Parameters\n",
    "Input the parameters of the topic model and run. The model has multiple parameters, including: \n",
    "- num_topics: Number of topics the model will generate (default = 100)\n",
    "- chunksize: Number of documents processed at a time (default = 2000)\n",
    "- passes: Number of times model is trained on corpus (default = 1)\n",
    "- iterations: Number of times model \"loops\" over each document (default = 50)\n",
    "\n",
    "Calculating coherence (above) helps determine topic number, and other methods can be used to determine appropriate values for the other parameters. \n",
    "\n",
    "**Chunk size:** Setting chunk size to a larger number than that of documents in the model ensures that all documents are processed at once (though this requires enough memory space). \n",
    "\n",
    "**Passes and Iterations:** A common way to determine the best number of passes and iterations is by training a topic model and checking the \"log\" to see the document convergence rate (what percentage of topic/word assignments attain stability). If convergence is low, increase number of passes and interations. \n",
    "\n",
    "In general, as chunksize increases, passes and iterations should increase as well. Also keep in mind that corpus size may effect number of topics--in the cases of smaller corpora, using too many topics will likely make them too general OR too limited to the context of only one text. Consider running multiple models and comparing coherence, perplexity, and top words per topic. \n",
    "\n",
    "Additional reading: \n",
    "\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#12buildingthetopicmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import logging to gauge passes and iterations; will output file to working directory\n",
    "import logging\n",
    "logging.basicConfig(filename='gensim.log',\n",
    "                    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 200\n",
    "chunksize = 1000\n",
    "passes = 20\n",
    "iterations = 40\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=1\n",
    ")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute C_V Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test LDA model multicore\n",
    "from gensim.models import ldamulticore\n",
    "from gensim import corpora, models\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 200\n",
    "chunksize = 1000\n",
    "passes = 400\n",
    "iterations = 6000\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "lda_model2 = models.LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    workers = cores-1,\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=1\n",
    ")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model2.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute C_V Coherence Score\n",
    "coherence_model_lda2 = CoherenceModel(model=lda_model2, texts=data_words, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda2.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Topic Model Output\n",
    "Once the model has been run, it is possible to retrieve the top words in each topic and visualing the model. These are methods can help further assess model coherence and point to future directions for analysis:\n",
    "- **Top Words Per Topic:** Evaluate to what extent each topic contains semantically similar words, how/why these words might be meaningful in context of corpus\n",
    "- **Visualizations:** Determine topic relatedness (how far apart topic circles are on plane) and topic prevalence (how large circles are corresponds to topic prevaence in corpus)\n",
    "\n",
    "Additional reading: \n",
    "\n",
    "https://towardsdatascience.com/6-tips-to-optimize-an-nlp-topic-model-for-interpretability-20742f3047e2\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#15visualizethetopicskeywords\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Print n number of words in each topic\n",
    "for idx, topic in lda_model2.print_topics(num_words=20):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary with topics and words\n",
    "my_dict = {\"Topic\":[],\"Words\":[]}\n",
    "for idx, topic in lda_model2.print_topics(num_words=20):\n",
    "    my_dict[\"Topic\"].append(idx)\n",
    "    my_dict[\"Words\"].append(topic)\n",
    "\n",
    "#Convert dictionary to dataframe\n",
    "topics_df = pd.DataFrame.from_dict(my_dict)\n",
    "topics_df.head()\n",
    "\n",
    "#Download dataframe as csv\n",
    "topics_df.to_csv('topic_word_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define word cloud function\n",
    "from wordcloud import WordCloud \n",
    "def create_wordcloud(model, topic):\n",
    "    text = {word: value for word, value in model.show_topic(topic)}\n",
    "    wc = WordCloud(background_color=\"white\", max_words=1000)\n",
    "    wc.generate_from_frequencies(text)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic\" + \" \"+ str(topic))\n",
    "    plt.show()\n",
    "    \n",
    "#Ignore depreciation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Create word clouds\n",
    "for i in range(1,num_topics):\n",
    "    create_wordcloud(lda_model2, topic=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create visualization of topic model above \n",
    "%matplotlib inline\n",
    "import pyLDAvis.gensim_models\n",
    "vis = pyLDAvis.gensim_models.prepare(topic_model=lda_model2, corpus=corpus, dictionary=dictionary, mds='mmds')\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, 'vis200_multicore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Top Topics Per Document\n",
    "\n",
    "Find the topic with highest percentage in each document in corpus. \n",
    "\n",
    "Additional reading: \n",
    "https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function that retrieves dominant topic for each document and puts in dataframe\n",
    "def format_topics_texts(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    text_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                text_topics_df = text_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    text_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    text_topics_df = pd.concat([text_topics_df, contents], axis=1)\n",
    "    return(text_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run dominant topic function on corpus\n",
    "df_topic_texts_keywords = format_topics_texts(ldamodel=lda_model, corpus=corpus, texts=data_words)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_texts_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Top Documents Per Topic\n",
    "Calculate the top documents attributed to each topic in the model. \n",
    "\n",
    "Additional reading:\n",
    "\n",
    "https://stackoverflow.com/questions/63777101/topic-wise-document-distribution-in-gensim-lda\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_methods.ipynb \n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/#7.-The-most-representative-sentence-for-each-topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Book + Chapter labels to dataframe for easier ID\n",
    "doc_names = df['Book + Chapter']\n",
    "df_topic_texts_keywords = df_topic_texts_keywords.join(doc_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most representative text for each topic \n",
    "#Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "#Create new dataframe and group topic keywords by dominant topic column\n",
    "topics_sorted_df = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_texts_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "#Sort data by percent contribution and select highest n values for each topic\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    topics_sorted_df = pd.concat([topics_sorted_df, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index of new df\n",
    "topics_sorted_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "topics_sorted_df.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\", \"Text Name\"]\n",
    "topics_sorted_df = topics_sorted_df.reindex(columns=['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text Name\", \"Representative Text\"])\n",
    "# Show\n",
    "topics_sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download top doc per topic to dataframe\n",
    "topics_sorted_df.to_csv('top_doc_per_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "**More Examples of Topic Modeling Research:**\n",
    "\n",
    "*   http://www.digitalhumanities.org/dhq/vol/11/2/000291/000291.html\n",
    "*   http://www.cs.columbia.edu/~blei/papers/Blei2011.pdf\n",
    "*   https://maria-antoniak.github.io/resources/2019_cscw_birth_stories.pdf \n",
    "\n",
    "**More Topic Modeling Tools:**\n",
    "\n",
    "*   https://github.com/polsci/colab-gensim-mallet/blob/master/topic-modeling-with-colab-gensim-mallet.ipynb\n",
    "*   https://github.com/laurejt/authorless-tms \n",
    "*   https://colab.research.google.com/github/kldarek/skok/blob/master/_notebooks/2021-05-27-Topic-Models-Introduction.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
