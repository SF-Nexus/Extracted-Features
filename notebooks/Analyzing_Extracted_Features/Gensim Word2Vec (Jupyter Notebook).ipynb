{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages and Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "import nltk\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get current working directory \n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "#Change working directory\n",
    "path = os.chdir(\"INSERT PATH\")\n",
    "\n",
    "#Upload dataframeâˆš\n",
    "df = pd.read_csv('INSERT NAME.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "#Can choose to lemmatize clean text with or without stopwords\n",
    "df['Text'] = df['Text'].apply(lambda x: ' '.join([wnl.lemmatize(word) for word in x.split() ]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up tokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "files_S = df['Text'].tolist()\n",
    "titles_S = df['Title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer function\n",
    "\n",
    "def make_sentences_S(list_text):\n",
    "    all_txt_S = []\n",
    "    counter = 0\n",
    "    for txt in tqdm(list_text, desc=\"Preprocessing\"):\n",
    "        lower_txt = txt.lower()\n",
    "        lemmas = [wnl.lemmatize(word) for word in lower_txt]\n",
    "        sentences_S = sent_tokenize(lower_txt)\n",
    "        sentences_S = [tokenizer.tokenize(sent) for sent in sentences_S]\n",
    "        all_txt_S += sentences_S\n",
    "        counter += 1\n",
    "    return all_txt_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "sentences_S = make_sentences_S(files_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model=gensim.models.Word2Vec(\n",
    "sentences_S, \n",
    "sg=1,\n",
    "min_count=2,\n",
    "vector_size=300,\n",
    "workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.save(\"Subset_model_real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Similarities + Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.most_similar(\"river\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.most_similar(\"toxic\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.most_similar(\"water\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.most_similar(\"polluted\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.most_similar(\"catastrophe\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.most_similar(\"foam\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.most_similar(\"forest\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('water','toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('water','sewer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('water','oxygen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('water','eastward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('river','sewer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('creek','sewer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('creek', 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('stream', 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('river', 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('air', 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('polluted', 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('forest', 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('river','sewer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_model.wv.similarity('ocean','sewer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Subset_model.wv.most_similar(positive=['river', 'canal'], negative=['ocean'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Subset_model.wv.most_similar(positive=['river', 'foam'], negative=['air'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Subset_model.wv.most_similar(positive=['river', 'sewage'], negative=['ocean'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Subset_model.wv.most_similar(positive=['water', 'toxic'], negative=['air'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Subset_model.wv.most_similar(positive=['river', 'flood'], negative=['air'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Subset_model.wv.most_similar(positive=['creek', 'sewer'], negative=['ocean'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Subset_model.wv.most_similar(positive=['river', 'polluted'], negative=['ocean'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup for plot\n",
    "\n",
    "base_words = ['toxic', 'pollution', 'river', 'water']\n",
    "toxic_similar_S = [i[0] for i in Subset_model.wv.most_similar(positive='toxic', topn=5)]\n",
    "pollution_similar_S = [i[0] for i in Subset_model.wv.most_similar(positive='pollution', topn=5)]\n",
    "river_similar_S = [i[0] for i in Subset_model.wv.most_similar(positive='river', topn=5)]\n",
    "water_similar_S = [i[0] for i in Subset_model.wv.most_similar(positive='water', topn=5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_S = np.hstack((base_words, toxic_similar_S, pollution_similar_S, river_similar_S, water_similar_S))\n",
    "print(all_words_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate similarities\n",
    "base_words = ['toxic', 'pollution', 'river', 'water', 'sewer', 'sewage', 'cleanse', 'clean', 'dirty', 'foam', 'infect', 'ocean', 'sea']\n",
    "\n",
    "similarities = []\n",
    "for word in base_words:\n",
    "    sim_words = Subset_model.wv.most_similar(word, topn=15)\n",
    "    similarities.append(sim_words)\n",
    "    \n",
    "similar_w_df = pd.DataFrame(similarities)\n",
    "similar_w_df = similar_w_df.T\n",
    "similar_w_df.columns = base_words\n",
    "similar_w_df.to_csv('subset_each_word_similarities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarities\n",
    "base_words = ['toxic', 'pollution', 'river', 'water', 'sewer', 'sewage', 'cleanse', 'clean', 'dirty', 'foam', 'infect', 'ocean', 'sea']\n",
    "\n",
    "similarities = []\n",
    "for word in base_words:\n",
    "    for other_word in base_words:\n",
    "        similarity_score = Subset_model.wv.similarity(word, other_word)\n",
    "        similarities.append((word, other_word, similarity_score))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(similarities, columns=['Word 1', 'Word 2', 'Similarity'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('INSERT NAME.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Similar Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot with color coding\n",
    "\n",
    "labels = [i for i in all_words_S]\n",
    "tokens = Subset_model.wv[labels]\n",
    "tokens = tokens.astype(float)\n",
    "\n",
    "tsne_model = TSNE(init='pca', learning_rate='auto', perplexity=15)\n",
    "new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "\n",
    "x= []\n",
    "y= []\n",
    "for value in new_values:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])\n",
    "    \n",
    "for word in all_words_S:\n",
    "    i=labels.index(word)\n",
    "    plt.annotate(labels[i],\n",
    "                xy=(x[i], y[i]),\n",
    "                xytext=(5, 2),\n",
    "                textcoords='offset points',\n",
    "                ha='right',\n",
    "                va='bottom')\n",
    "    if word in toxic_similar_S:\n",
    "        plt.scatter(x[i], y[i], color='gold')\n",
    "    elif word == 'toxic':\n",
    "         plt.scatter(x[i], y[i], color='goldenrod')\n",
    "    elif word in pollution_similar_S:\n",
    "         plt.scatter(x[i], y[i], color='indianred')\n",
    "    elif word == 'pollution':\n",
    "         plt.scatter(x[i], y[i], color='brown')\n",
    "    elif word in river_similar_S:\n",
    "         plt.scatter(x[i], y[i], color='silver')\n",
    "    elif word == 'river':\n",
    "         plt.scatter(x[i], y[i], color='grey')\n",
    "    elif word in water_similar_S:\n",
    "         plt.scatter(x[i], y[i], color='lightblue')\n",
    "    elif word == 'water':\n",
    "        plt.scatter(x[i], y[i], color='royalblue')\n",
    "    plt.title(\"Word2Vec Embeddings from Water Novel Subset\", fontweight='bold' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
