{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6494322",
   "metadata": {},
   "source": [
    "# Mapping Semantic Similarity with Atlas \n",
    "\n",
    "Atlas is a platform for interacting with both small and internet scale unstructured datasets. It was developed by Nomic, the world's first information cartography company, and allows for researchers to cluster and map texts based on semantic similarity. Below, texts are prepared for ingestion into Atlas, and the pipeline is run to serve a map of text embeddings to https://atlas.nomic.ai. To use this pipeline, first go to https://home.nomic.ai/ and create an account.\n",
    " \n",
    "Atlas Documentation: https://docs.nomic.ai/\n",
    "\n",
    "Example Code: https://github.com/nomic-ai/nomic/blob/main/examples/map_text.py\n",
    "\n",
    "Example Output: https://atlas.nomic.ai/map/wiki500k "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33776203",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4b688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install nomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log in with nomic through command line \n",
    "!nomic login #[insert token; run without to generate token for first time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa55c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nomic import AtlasClient\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "atlas = AtlasClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877a860",
   "metadata": {},
   "source": [
    "## Upload Texts for Mapping (CSV File Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a77fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#Get current working directory \n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "#Change working directory\n",
    "path = os.chdir(\"/PATHNAME\")\n",
    "\n",
    "#Upload dataframeâˆš\n",
    "df = pd.read_csv('filename.csv')\n",
    "\n",
    "#Drop first column (unnamed)\n",
    "df = df.iloc[: , 1:]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06587d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "sentences = df['Text'].tolist()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = AutoModel.from_pretrained(\"prajjwal1/bert-mini\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-mini\")\n",
    "model\n",
    "\n",
    "#Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da60ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbf737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d12aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to np array \n",
    "sentence_embeddings = sentence_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29177e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set metadata\n",
    "df['Title'] = df['Title'].astype(str)\n",
    "title = df['Title'].tolist()\n",
    "title\n",
    "\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "genre = df['Genre'].tolist()\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'title': title[i % len(title)], 'genre': genre[i % len(genre)],'id': i}\n",
    "            for i in range(len(sentence_embeddings))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa44784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = atlas.map_embeddings(embeddings=sentence_embeddings,\n",
    "                                is_public=True,\n",
    "                                data=data,\n",
    "                                colorable_fields=['genre'],\n",
    "                                map_name=\"Modeling Science Fiction, Fantasy and Detective Fiction\",\n",
    "                                map_description=\"Map of texts from Temple University's Science Fiction Collection and Project Gutenberg.\",\n",
    "                               )\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
