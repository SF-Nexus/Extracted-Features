{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modeling with SciFi Corpus.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "40KVswYbunE3",
        "f4qStMOwuvYK",
        "MI34VMFq801e"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Text-Mining-Experiments/blob/main/Topic_Modeling_with_SciFi_Corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXOw5gPaRLuQ"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "What are the most common topics in a corpus of science fiction texts? Which texts tend to address the same topics, and why? These are just a couple of the many questions which this code addresses. Below, Gensim is used to create LDA topic models of a pre-loaded dataframe of texts. \n",
        "\n",
        "This code is adapted from this [Intro to Topic Modeling with Gensim and pyLDAvis](https://github.com/hawc2/text-analysis-with-python/blob/master/Topic_Modeling.ipynb) and works well with input from from the Text Sectioning and Disaggregation code from [this repository](https://github.com/SF-Nexus/Extracted-Features/blob/main/Text_Sectioning_and_Disaggregation_in_Python.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Packages"
      ],
      "metadata": {
        "id": "jfm_YfxIRWjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "GNIhKdGeRWH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install spacy\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "iTVMYYbCRdhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "metadata": {
        "id": "MvASJDYpRfNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "id": "FZkNZc4lRhTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "EjAj_KoORnfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxEMrysjRHwB"
      },
      "source": [
        "# Retrieve and Convert File to Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OJjCRA2y8_fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC1izyiZG8EJ"
      },
      "source": [
        "#Upload files\n",
        "#Recommended file type: csv file containing \"bag of words\" like chapters_sample.csv in this repo\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUM-atjwy0mm"
      },
      "source": [
        "#Install necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "#Convert csv to dataframe\n",
        "df = pd.read_csv(io.StringIO(uploaded['word_chunks_bag_of_words_output (1).csv'].decode('utf-8')))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo-GqUxGy_dY"
      },
      "source": [
        "#Add values in Text column to new list (for further cleaning)\n",
        "data = df.Text.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EocrECQchTEF"
      },
      "source": [
        "#View dataframe as Colab data table\n",
        "%load_ext google.colab.data_table \n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7B4L5MRRFJH"
      },
      "source": [
        "# Clean Texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRgCvQRfOOE"
      },
      "source": [
        "#Define list of stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Add further stopwords by simply \"appending\" desired words to dictionary\n",
        "#stop_words.append('movie')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQXKsWbxrsUg"
      },
      "source": [
        "#Remove punctuation\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFPfCl6nHHjT"
      },
      "source": [
        "#Define function to perform simple preprocessing on text\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "      yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9saf7oBhoRdy"
      },
      "source": [
        "#Run processing function on texts\n",
        "data_words = list(sent_to_words(data))\n",
        "print(data_words[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOtbz8fXfgCt"
      },
      "source": [
        "#Define bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=1, threshold=100)\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4qFCAGQfgvA"
      },
      "source": [
        "#Define stopword removal\n",
        "def remove_stopwords(texts):\n",
        "   return [[word for word in simple_preprocess(str(doc))\n",
        "if word not in stop_words] for doc in texts]\n",
        "\n",
        "#Define function to make bigrams\n",
        "def make_bigrams(texts):\n",
        "   return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "#def make_trigrams(texts):\n",
        "#   return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "#Define function to lemmatize texts\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "   texts_out = []\n",
        "   for sent in texts:\n",
        "     doc = nlp(\" \".join(sent))\n",
        "     texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "   return texts_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRMeqTfHkey6"
      },
      "source": [
        "#Run functions to remove stopwords, make bigrams, and lemmatize text\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=[\n",
        "   'NOUN', 'ADJ', 'VERB', 'ADV'\n",
        "])\n",
        "print(data_lemmatized[:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctV_0V95kj1p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JXqo5CI47kE"
      },
      "source": [
        "# Building Dictionary and Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf46pDnu4CNX"
      },
      "source": [
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "texts = data_lemmatized\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EExpaCS7SInJ"
      },
      "source": [
        "# Create Topic Model - Topics 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqbXMdeAHIq5"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20,\n",
        "                                           random_state=100,\n",
        "                                           update_every=2,\n",
        "                                           chunksize=100,\n",
        "                                           passes=20,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3_bC9dfS0q3"
      },
      "source": [
        "# Create Visualization (Save HTML)\n",
        "\n",
        "The easiest way to create the visualization is to reveal it in the Google Colab notebook and save it as an html file that you can view on your browser. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz2SdZiGtzcb"
      },
      "source": [
        "!pip install pyLDAvis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKhTNneQHJ1C"
      },
      "source": [
        "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "\n",
        "#vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk7mOcrnktEp"
      },
      "source": [
        "pyLDAvis.save_html(vis, '/content/LDAviz.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z83wjLBgsedR"
      },
      "source": [
        "pyLDAvis.display(vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH4WlWezsHNy"
      },
      "source": [
        "# Topic Modeling Model - 60 Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSu3f89PsGtI"
      },
      "source": [
        "lda_model60 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=60,\n",
        "                                           random_state=100,\n",
        "                                           update_every=2,\n",
        "                                           chunksize=100,\n",
        "                                           passes=20,\n",
        "                                           iterations=200,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7lb7hEasr9u"
      },
      "source": [
        "# Create Visualization (Save HTML)\n",
        "\n",
        "The easiest way to create the visualization is to reveal it in the Google Colab notebook and save it as an html file that you can view on your browser. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lst_Wcwsr-J"
      },
      "source": [
        "vis60 = pyLDAvis.gensim.prepare(lda_model60, corpus, id2word)\n",
        "#vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJBuBBcGsr-Q"
      },
      "source": [
        "pyLDAvis.save_html(vis60, '/content/LDAviz60.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LnUVVOJsr-X"
      },
      "source": [
        "pyLDAvis.display(vis60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI34VMFq801e"
      },
      "source": [
        "# Serve Visualization in Browser\n",
        "\n",
        "You can also serve the visualization locally in the browser using the below chunk of code. Beware that caching in your browser and other issues, such as ad-blockers, may require some debugging to get this working on your machine. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn8XNwM58zrM"
      },
      "source": [
        "#pyLDAvis.enable_notebook()\n",
        "#pyLDAvis.show(vis)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
